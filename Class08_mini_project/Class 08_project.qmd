---
title: "Class 8: PCA mini project"
author: "Dora Deng (A17445600)"
format: pdf
---

Today we will do a complete analysis of some breast cancer biospy data but first let's revist the main PCA function in R `prcomp()` and see what `scale=TRUE/FALSE` does. 

```{r}
head(mtcars)

```

Find the mean value per column of this dataset? 

```{r}
apply(mtcars, 2, mean)
```

```{r}
apply(mtcars, 2, sd)
```

It is clear "disp" and "hp" have the highest mean values and the highest standard deviation. They will likely dominate any analysis I do on this dataset. Let's see. 

```{r}
pc.noscale <-prcomp(mtcars)
pc.scale <- prcomp(mtcars, scale = TRUE)
```

```{r}
biplot(pc.noscale)
```

```{r}
pc.noscale$rotation [,1]
```

plot the loadings 

```{r}
library(ggplot2)

r2 <-  as.data.frame(pc.scale$rotation) 
r2$names <- rownames(pc.scale$rotation)

ggplot(r2)+
  aes(PC1, names)+ 
  geom_col()
```

```{r}
biplot(pc.scale)
```


> **Take-home**: Generally we always want to set `scale = TRUE` when we do this type of analysis to avoid our analyses being dominated by individual variables with the largest variance just due to their unit of measurement. 

# FNA breast cancer data

Load the data into R. 
```{r}
wisc.df <- read.csv("WisconsinCancer.csv", row.names = 1)
head(wisc.df)
```

>Q1. How many observations are in this dataset?
569 observations

```{r}
nrow(wisc.df)
```

>Q2. How many of the observations have a malignant diagnosis?
212 have a malignant diagnosis. 

```{r}
sum(wisc.df$diagnosis == "M")

```
The `table()` function is super useful here. 

```{r}
table(wisc.df$diagnosis)
```

>Q3. How many variables/features in the data are suffixed with _mean?
31 

```{r}
ncol(wisc.df)
```

```{r}
colnames(wisc.df)
```

A useful function for this is `grep()`

```{r}
length(grep("_mean",colnames(wisc.df)))
```

Before we go any further we need to exclude the diagnoses column form any future analysis - this tells us whether a sampe to cancer or non-cancer. 

```{r}
diagnosis <- as.factor(wisc.df$diagnosis)
head(diagnosis)
```

```{r}
wisc.data <- wisc.df[,-1]
```

Let's see if we can cluster the `wisc.data` to find some structure in the dataset. 

```{r}
hc <- hclust(dist(wisc.data))
plot(hc)

```

# Principal Component Analysis (PCA)
```{r}
colMeans(wisc.data)

apply(wisc.data,2,sd)
```

```{r}
wisc.pr <- prcomp(wisc.data,scale = TRUE)
summary(wisc.pr)
```

>Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?
0.4427
 
>Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
 3 

>Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
7

```{r}
biplot(wisc.pr)
```
> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?
This plot is difficult to read and to identity any relatioship from this plot. 
This biplot sucks! We need to build our own PCA score plot of PC1 vs PC2. 

```{r}
attributes(wisc.pr)
```

```{r}
head(wisc.pr$x)
```

Plot of PC1 vs PC2 the first two columns 

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis)
```
>Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?
Plot one has a more clear cut in separating the two types of cancer. 

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], col=diagnosis)
```


Make a ggplot version of this score plot 

```{r}
pc <- as.data.frame(wisc.pr$x)

ggplot(pc)+
  aes(PC1, PC2, col = diagnosis)+
  geom_point()
```

```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var) 
```

```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```


> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?
-0.2608538

```{r}
#concave.points_mean()
wisc.pr$rotation["concave.points_mean",1]
```


>Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?
5 PCs

```{r}
summary(wisc.pr)
```


# Hierarchical clustering

# Scale the wisc.data data using the "scale()" function
```{r}
data.scaled <- scale(wisc.data)
```

```{r}
data.dist <- dist(data.scaled)
```

> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?
 19 is the height for 4 clusters. 
 
```{r}
wisc.hclust <- hclust(data.dist)
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust,k=4)
table(wisc.hclust.clusters, diagnosis)
```


> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?
I think when we cut the data into 8 clusters, it could possibly give you a better result for diagnosis. However, there are trade-off in this because there are still some false positive in cluster 1 for examples and a lot false negative in cluster 4. 

## Clustering in PC space 
```{r}
hc <- hclust(dist(wisc.pr$x[,1:2]), method = "ward.D2") 
plot (hc)
abline(h=70, col = "red")
```

> Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.
I think `ward.D2` gives the best result in my opinion since I think the others give an skewed result, and it provides a clear way to cut the cluster tree. 

Cluster membership vector: 

```{r}
grps <- cutree(hc, h=70)
table(grps)
```

```{r}
table(diagnosis)
```

Cross-table to see how my clustering groups crrespond to the expert diagnosis vector of M and B values 

```{r}
table(grps, diagnosis)
```

Positive -> cancer M 
Negative -> non-cancer B 

True = cluster/ group 1 
False = cluster/ group 2 

True positive = 177 
False positive = 18 
True negative = 339 
False negative = 35

# OPTIONAL: K-means clustering

```{r}
wisc.km <- kmeans(scale(wisc.data), centers= 2, nstart= 20)
table(wisc.km$cluster, diagnosis)
```

>Q14. How well does k-means separate the two diagnoses? How does it compare to your hclust results?
K-means has 37 false negatives (9.7%) and 14 false positive (7.4%), and hclust gives false positive 9.2% of the time and false negative 9.4% of the time. It seems like that K-means has a better specificity while hclust has a better sensativity. 

```{r}
table(wisc.km$cluster, wisc.hclust.clusters)
```

#Combining Methods


```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:7]), method = "ward.D2") 
```

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
```
```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
```
```{r}
g <- as.factor(grps)
levels(g)
```

```{r}
g <- relevel(g,2)
levels(g)
```
```{r}
plot(wisc.pr$x[,1:2], col=g)
```

```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
wisc.pr.hclust <- hclust(dist(wisc.pr$x[, 1:7]), method="ward.D2")
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```


```{r}
# Compare to actual diagnoses
table(wisc.pr.hclust.clusters, diagnosis)
```
> Q15. How well does the newly created model with four clusters separate out the two diagnoses?
It separates cluster 1 with mainly malignant cancer cases with 28 cases of false positive, and cluster 2 with mainly benevolent cases with 24 cases of false negative. It successfully separate most of the cases but still have a decent amount of false positives and false negatives, which would be problematic if the results are to be delivered to patients. 


```{r}
# k-means clustering: 
table(wisc.km$cluster, diagnosis)
```

```{r}
# Hierarchical clustering
table(wisc.hclust.clusters, diagnosis)
```
> Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.
They both separate groups with false positives and negatives. K-means clustering separates into two clusters, while hclust clustering separates into multiple clusters. K-means could make more errors and hclust is relatively more accurate but it splits into more groups for diagnosis. 

>Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity? 
k-means clustering produces a 92.6% sensitivity and 90.3% specificity. Hierarchical clustering produces a 92.4% sensitivity and 89.8% specificity.K-means has a higher sensitity and specificity. (Sensitivity was calculated by True Positive / (True positive + False negative) and specificity was calculated by True negative / (True negative + False positive)).


## Prediction 
We can use our PCA results (wisc.pr) to make predictions on new unseen data. 

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> Q18. Which of these new patients should we prioritize for follow up based on your results?
I think we should prioritize group 2 patients because the data shows a similar pattern as those who we have seen to be diagnosed as having true positive or malignant cancer.   


